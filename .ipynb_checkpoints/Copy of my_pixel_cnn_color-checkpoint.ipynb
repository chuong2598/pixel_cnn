{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 1279,
     "status": "ok",
     "timestamp": 1612861123015,
     "user": {
      "displayName": "Chuong Nguyen",
      "photoUrl": "",
      "userId": "04095122113401909297"
     },
     "user_tz": -660
    },
    "id": "pxMlo2FCaJiP",
    "outputId": "42401015-4b28-46ed-e9a7-cc897d7687d9"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "# import UserWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2607,
     "status": "ok",
     "timestamp": 1612861126403,
     "user": {
      "displayName": "Chuong Nguyen",
      "photoUrl": "",
      "userId": "04095122113401909297"
     },
     "user_tz": -660
    },
    "id": "UCJePAU9aWAH",
    "outputId": "44b7a24f-1553-4fa9-d105-2527bccf2fda"
   },
   "outputs": [],
   "source": [
    "\n",
    "training_set = torch.utils.data.DataLoader(torchvision.datasets.MNIST('data', train=True, download=True, transform=torchvision.transforms.ToTensor()),\n",
    "                     batch_size=16, shuffle=True)\n",
    "validation_set = torch.utils.data.DataLoader(torchvision.datasets.MNIST('data', train=False, download=True, transform=torchvision.transforms.ToTensor()),\n",
    "                     batch_size=16, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VerticalMaskedConv2d(torch.nn.Conv2d):\n",
    "    \n",
    "    def __init__(self, device=\"cpu\", *arg, **kargs):\n",
    "        super(VerticalMaskedConv2d, self).__init__(*arg, **kargs)\n",
    "#         print(self.kernel_size)\n",
    "        self.padding = (self.kernel_size[0] // 2, self.kernel_size[1] // 2)\n",
    "        \n",
    "        self.mask = torch.ones_like(self.weight.data)\n",
    "        self.mask[:, :, self.kernel_size[0]//2:] = 0\n",
    "        self.mask = self.mask.to(device)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        self.weight.data = self.weight.data * self.mask\n",
    "        pred = super(VerticalMaskedConv2d, self).forward(images)\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test vertical conv2d\n",
    "vertical_mask = VerticalMaskedConv2d(in_channels=5, out_channels=3, kernel_size=(7,7))\n",
    "test_tensor = torch.randn(1, 5, 16, 16)\n",
    "test_result = vertical_mask(test_tensor)\n",
    "print(test_result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HorizontalMaskedConv2d(torch.nn.Conv2d):\n",
    "    \n",
    "    def __init__(self, mask_type, device=\"cpu\", *arg, **kargs):\n",
    "        super(HorizontalMaskedConv2d, self).__init__(*arg, **kargs)\n",
    "\n",
    "        self.padding = (0, self.kernel_size[1] // 2)\n",
    "        batch, channel, height, width = self.weight.data.shape\n",
    "        \n",
    "        self.mask = torch.ones_like(self.weight.data)\n",
    "        self.mask[:,:,0, width//2:] = 0\n",
    "        if mask_type == \"B\":\n",
    "             self.mask[:, :, 0, width//2] = 1        \n",
    "        self.mask = self.mask.to(device)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        self.weight.data = self.weight.data * self.mask\n",
    "        pred = super(HorizontalMaskedConv2d, self).forward(images)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# horizontal_mask = HorizontalMaskedConv2d(mask_type=\"A\", in_channels=1, out_channels=1, kernel_size=(1,11))\n",
    "# test_tensor = torch.randn(1, 1, 16, 16)\n",
    "# test_result = horizontal_mask(test_tensor)\n",
    "# print(test_result.shape)\n",
    "# print()\n",
    "\n",
    "# horizontal_mask = HorizontalMaskedConv2d(mask_type=\"B\", in_channels=1, out_channels=1, kernel_size=(1,11))\n",
    "# test_tensor = torch.randn(1, 1, 16, 16)\n",
    "# test_result = horizontal_mask(test_tensor)\n",
    "# print(test_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "executionInfo": {
     "elapsed": 1080127,
     "status": "aborted",
     "timestamp": 1612847283627,
     "user": {
      "displayName": "Chuong Nguyen",
      "photoUrl": "",
      "userId": "04095122113401909297"
     },
     "user_tz": -660
    },
    "id": "AcqaQ8W0Gqiq"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Gated_Conv_Block(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, horizontal_mask_type, in_channels, out_channels, kernel_size):\n",
    "        super(Gated_Conv_Block, self).__init__()\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.vertical_conv = VerticalMaskedConv2d(in_channels=in_channels, out_channels=out_channels*2, kernel_size=kernel_size)\n",
    "        self.vertical_to_horizontal_conv = torch.nn.Conv2d(in_channels=out_channels*2, out_channels=out_channels*2, kernel_size=1, padding=0)\n",
    "        self.horizontal_conv = HorizontalMaskedConv2d(mask_type=horizontal_mask_type, in_channels=in_channels, \n",
    "                                                             out_channels=out_channels*2, kernel_size=(1, kernel_size))\n",
    "        self.res_conv = torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, images):\n",
    "        v_conv = self.vertical_conv(images)\n",
    "        v_tanh, v_sigmoid = torch.split(tensor=v_conv, split_size_or_sections=self.out_channels, dim=1)\n",
    "        v_output = torch.tanh(v_tanh) * torch.sigmoid(v_sigmoid)\n",
    "        \n",
    "        v_to_h = self.vertical_to_horizontal_conv(v_conv)\n",
    "        h_conv = self.horizontal_conv(images)\n",
    "        h_conv = h_conv + v_to_h\n",
    "        h_tanh, h_sigmoid = torch.split(tensor=h_conv, split_size_or_sections=self.out_channels, dim=1)\n",
    "        h_res = torch.tanh(h_tanh) * torch.sigmoid(h_sigmoid)\n",
    "        h_res = self.res_conv(h_res)\n",
    "        h_output = images + h_res\n",
    "        return v_output, h_output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test gated conv\n",
    "gated_conv = Gated_Conv_Block(horizontal_mask_type=\"A\", in_channels=1, out_channels=5, kernel_size=5)\n",
    "test_input = torch.randn(3, 1, 16, 16)\n",
    "# v_output, h_output = gated_conv(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Gated_Pixel_CNN_Mnist(torch.nn.Module):\n",
    "    def __init__(self, nb_gated_block, hidden_layer_dim, in_channels, out_channels, kernel_size):\n",
    "        super(Gated_Pixel_CNN_Mnist, self).__init__()\n",
    "        \n",
    "        self.nb_gated_block = nb_gated_block\n",
    "        self.first_gated_block = Gated_Conv_Block(horizontal_mask_type=\"A\", in_channels=in_channels, \n",
    "                                                  out_channels=hidden_layer_dim, kernel_size=kernel_size)\n",
    "        \n",
    "        self.gated_block_list = []\n",
    "        self.batch_norm_list = []\n",
    "        for i in range(1, nb_gated_block):\n",
    "            new_cell = Gated_Conv_Block(horizontal_mask_type=\"B\", in_channels=hidden_layer_dim, \n",
    "                                                  out_channels=hidden_layer_dim, kernel_size=kernel_size)\n",
    "            self.gated_block_list.append(new_cell)\n",
    "            self.batch_norm_list.append(torch.nn.BatchNorm2d(hidden_layer_dim))\n",
    "        self.gated_block_list = torch.nn.ModuleList(self.gated_block_list)\n",
    "        self.batch_norm_list = torch.nn.ModuleList(self.batch_norm_list)\n",
    "        \n",
    "        self.last_conv = torch.nn.Conv2d(in_channels=hidden_layer_dim, out_channels=out_channels, kernel_size=1)\n",
    "        \n",
    "\n",
    "    def forward(self, images):\n",
    "        v_output, h_output = self.first_gated_block(images)\n",
    "        for i in range(self.nb_gated_block-1):\n",
    "            v_output, h_output = self.gated_block_list[i](h_output)\n",
    "            h_output = self.batch_norm_list[i](h_output)\n",
    "        pred = self.last_conv(h_output)\n",
    "        return pred\n",
    "\n",
    "gated_pixel_cnn = Gated_Pixel_CNN_Mnist(nb_gated_block=10, hidden_layer_dim=128, in_channels=1, out_channels=2, kernel_size=5)\n",
    "gated_pixel_cnn.to(device=device)\n",
    "optim = torch.optim.Adam(gated_pixel_cnn.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea893331e69d4b269ec37129d507d75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3750.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for images, label in tqdm(training_set):\n",
    "        images = images.to(device)\n",
    "        pred = gated_pixel_cnn(images)\n",
    "        loss = torch.nn.CrossEntropyLoss()(pred, images[:,0,...].long())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()(pred, images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPEvmmmh38IkPVW8uc2DFyb",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of my_pixel_cnn_color.ipynb",
   "provenance": [
    {
     "file_id": "1DQlrDX_O42s3j_mkQMgiVic778PC6kT9",
     "timestamp": 1612844638659
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2c3a930349d44886ab079366ae1016c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6282822bfd664d8e91e583ea33fabc17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "628915dbe94f4189ab7fa512a2c86495": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "999933ab742040ab8f7f7e7d596d6b32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e68b9ac7d52749558b6826566f888569",
      "placeholder": "​",
      "style": "IPY_MODEL_6282822bfd664d8e91e583ea33fabc17",
      "value": " 2977/3125 [08:29&lt;00:25,  5.85it/s]"
     }
    },
    "a075ab02d45b470689d0d5a2d3b9f1e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d00d9a6fa8ac4b31af43e16b89c06c8a",
       "IPY_MODEL_999933ab742040ab8f7f7e7d596d6b32"
      ],
      "layout": "IPY_MODEL_628915dbe94f4189ab7fa512a2c86495"
     }
    },
    "c29c79d0708b418588ef96370d4c91a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d00d9a6fa8ac4b31af43e16b89c06c8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 95%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c3a930349d44886ab079366ae1016c4",
      "max": 3125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c29c79d0708b418588ef96370d4c91a8",
      "value": 2977
     }
    },
    "e68b9ac7d52749558b6826566f888569": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
